//! The traversal sequence generator (bijective sponge).

// TODO: Get rid of this all-together.

use std::hash::{Hash, Hasher};

/// Permute an integer pseudorandomly.
///
/// This is a bijective function emitting chaotic behavior. Such functions are used as building
/// blocks for hash functions.
fn sigma(x: u8) -> u8 {
    /// A permutation table.
    ///
    /// It is generated by generating a cycle by going through all the integers, several thousand
    /// times, then permuting them based on a pseudorandom stream based on 1024 of PCG round, then
    /// the table is reordered to be full-cycle.
    static TABLE: [u8; 256] = [
         13, 103, 249, 200, 212, 207,  40,  84, 229, 204, 219, 135,  92, 148, 106, 139,  95, 152,
         49,  55, 132,   2,  30, 186, 108, 213, 159, 224, 111,  68,  37, 178, 129, 157, 247,  54,
         81,  56, 223,  28, 174,  87, 166,   6, 217,  41,  67, 161,   4, 205, 201, 211, 254, 171,
        208,  52,  18, 115, 194, 142,   7, 104, 164, 234, 126, 203, 233, 138,  97, 222, 124, 168,
        151,  91, 112,  63,  78, 144,  98, 119, 246,  26, 187, 150, 145,  64,  51, 136,  96,  85,
         46,  12, 218, 154,  25,  53, 240, 206, 192, 215, 160,  60, 190,  42, 116, 127, 110, 114,
         21,   9, 199, 173, 133,   1, 243,  73,  20, 176, 181, 184, 209, 237, 225, 180, 189,  86,
         72, 128,  43,  39, 123, 163, 248, 167,  44, 188,  29,  24, 179, 221,   8,  47, 255,  36,
         15, 228,  83, 149,  70, 153,  35,  16,  65, 216, 121,  88, 227, 183, 197, 118, 109, 232,
         99, 245, 120, 230, 155,  38,  79,  27,  71, 252, 147, 140, 244, 195,   3, 241,  34,  14,
        214,  23, 202,  77, 250,  31, 238, 158,  62, 226,  19, 231, 235, 172,  75,  50, 253,  89,
        101, 107, 102, 169, 177,  76,  69,  57,  74, 134, 170, 146, 198,  48,  61,  80, 182,  66,
         22,  17, 117,   0, 236,  10, 122,  82, 196,  58, 131,  94, 162, 191, 220, 100, 242, 130,
          5, 125,  59, 137,  90, 175, 141, 251, 239, 185,  32, 193,  33, 210, 143, 105,  93, 165,
        113, 156,  11,  45,
    ];

    // Simply permute based on the lookup table.
    TABLE[x as usize]
}

/// A sponge.
///
/// Sponges can be written to and then squeezed, which extracts a pseudorandom number. Given enough
/// of the squeezing stream, it should be possible to reconstruct the written input in its entire.
/// In other words, given enough of the output streams of two distinct inputs, they are not equal.
/// Hence, there will eventually be no collisions.
///
/// The idea of this is that we want to randomly generate hash values, but we want to avoid
/// collisions, which can otherwise make the hash tables incorrect (there is no exact collision
/// resolution).
///
/// # Example of a bijective sponge
///
/// Suppose `1` and `2` both generate the stream
///
///     1, 2 → 233, 21, 34, 54
///
/// If we read more of the stream of `1` and the stream of `2`, the two streams will eventually
/// diverge:
///
///     1    → 233, 21, 34, 54, 242
///     2    → 233, 21, 34, 54, 32
///
/// # How the this bijective sponge works
///
/// The way it works is reading the input and bijectively updating the state based on the input. An
/// internal buffer with all the states are held. To make sure output depends on the higher input,
/// and not just the lower, we do the same in reverse: The output extracted updates a state,
/// defining a permutation, which is applied to the byte read from the internal buffer.
///
/// To avoid ambiguities with different lengths, we length pad the stream.
///
/// ## Example
///
/// Suppose our input stream is
///
///     1, 2, 3
///
/// (we ignore length padding, which simply means appending the length here)
///
/// Then we start with state `0`, we then write into our internal buffer
///
///     σ(0 ⊕ 1) = σ(1)
///
/// Next, we read `2`, yielding internal buffer of
///
///     σ(1), σ(σ(1) ⊕ 2)
///
/// Then `3`, giving us
///
///     σ(1), σ(σ(1) ⊕ 2), σ(σ(σ(1) ⊕ 2) ⊕ 3)
///
/// This can be reverted by taking the first, inverting the permutation, then inverting the next,
/// and XORing with the first, and then using that information to invert the last.
///
/// However, it fails to have the lower items depend on the higher. To combat this, we have a
/// special way of squeezing:
///
/// When we start squeezing, we set the state to `0` again. Then we pop the highest byte from the
/// internal buffer, which is then XOR'd with the state and permuted by σ. This gives the new state
/// and the extracted byte.
#[derive(Default, Clone)]
pub struct Sponge {
    /// The state of the sponge.
    ///
    /// This is equal to the last outputted byte (and if none, the last byte in the buffer).
    state: u8,
    /// The internal buffer.
    buffer: Vec<u8>,
}

impl Sponge {
    /// Create a new sponge for hashing a particular key.
    pub fn new<T: Hash>(key: &T) -> Sponge {
        // Initialize the sponge.
        let mut sponge = Sponge::default();

        // Write the key into the sponge.
        key.hash(&mut sponge);

        // Switch to squeezing.
        sponge.begin_squeeze();

        sponge
    }

    /// Extract an output byte from the sponge.
    pub fn squeeze(&mut self) -> u8 {
        // We the popped byte XOR by the state and then permute through the table.
        self.state = sigma(self.state ^ self.buffer.pop().unwrap_or(0));

        self.state
    }

    /// Truncate the sponge to match another sponge.
    ///
    /// This truncates and sets state of the sponge under the assumption that the two sponges have
    /// outputted matching streams so far. As a result, the sponge is put in a state, which is
    /// supposed to be equal to the state, which would otherwise be achieved by squeezing the
    /// sponge as much as `other`.
    pub fn matching(&mut self, other: &Sponge) {
        // These are matching, as the two sponges are assumed to have outputted the same bytes so
        // far.
        self.state = other.state;
        // Next, truncate the buffer, so the internal buffers are of same length.
        self.buffer.truncate(other.buffer.len());
    }

    /// Go to squeezing state.
    ///
    /// This does length padding, thus ensuring bijectivity.
    fn begin_squeeze(&mut self) {
        // Pad with the length.
        // TODO: When non-lexical lifetimes land, merge the two following lines.
        let len = self.buffer.len();
        self.write_usize(len);
        // Zero the state.
        self.state = 0;
    }
}

impl Hasher for Sponge {
    fn finish(&self) -> u64 {
        // You can't produce a u64 from a sponge. It is designed to produce an endless sequence of
        // bytes.
        unreachable!();
    }

    fn write(&mut self, bytes: &[u8]) {
        // Write each byte one-by-one.
        // TODO: This could be faster.
        for &i in bytes {
            self.write_u8(i);
        }
    }

    fn write_u8(&mut self, i: u8) {
        // Mix in the state and permute.
        self.state = sigma(self.state ^ i);
        // The new state is then pushed to the buffer to be extracted later.
        self.buffer.push(self.state);
    }
}
